{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24539e83-605c-49cf-a0eb-069447a4ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53d69ce-693a-4bbd-8726-f35c0902a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "api_key = \"OpenAi api key\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf38745-0e39-4e86-b3ce-5bcab692feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "# def extract_pdf_text(pdf_path):\n",
    "#     text = \"\"\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page in pdf.pages:\n",
    "#             text += page.extract_text()  # Extract normal text\n",
    "#             tables = page.extract_tables()  # Extract tables\n",
    "#             for table in tables:\n",
    "#                 for row in table:\n",
    "#                     text += \" | \".join(str(cell) if cell else \"\" for cell in row) + \"\\n\"\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9366ae2d-49bc-439e-b412-e1cb85750e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text(file_path):\n",
    "    text = \"\"\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "    elif file_path.lower().endswith('.docx'):\n",
    "        doc = Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a631b76-dd34-4c3d-b215-21184a3a55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_system(pdf_path):\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    text = extract_pdf_text(pdf_path)\n",
    "\n",
    "    print(\"Splitting text into chunks...\")\n",
    "    # Split text into smaller chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    print(\"Creating embeddings and vector store...\")\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    vector_store = Chroma.from_texts(chunks, embeddings)\n",
    "\n",
    "    # Create Retrieval-based QA system\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(model=\"gpt-4\", temperature= 0),\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9063c575-bb1a-4a06-93af-bc812b48c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_qna():\n",
    "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
    "    qa_chain = prepare_qa_system(pdf_path)\n",
    "\n",
    "    print(\"\\nPDF QnA system is ready! Type your questions below.\\n\")\n",
    "    while True:\n",
    "        query = input(\"Q: \")\n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Exiting the QnA system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        result = qa_chain.invoke({\"query\": query})\n",
    "        print(f\"A: {result['result']}\\n\")\n",
    "        for doc in result[\"source_documents\"]:\n",
    "            print(f\"[Source]: {doc.metadata.get('source', 'No source')}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaaeccf-8876-4aaa-ac85-5a32b261b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the PDF file:  sample.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Splitting text into chunks...\n",
      "Creating embeddings and vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_25368\\239044759.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_25368\\239044759.py:18: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm=ChatOpenAI(model=\"gpt-4\", temperature= 0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDF QnA system is ready! Type your questions below.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  How much was Infosys' goodwill as of March 31, 2024?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Infosys' goodwill as of March 31, 2024 was â‚¹7,303 crore.\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_qna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a269e-1502-47d0-bbe7-e5e46a25a3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
