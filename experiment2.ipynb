{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba18602-8ecc-4212-92d7-51c9deb28f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b276430c-bceb-4747-9215-4b9368167339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading PDF, DOCX and TXT files as LangChain Documents\n",
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "\n",
    "# wikipedia\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5042a739-e7e8-42f6-a40a-11caaa9b892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=7500, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d7bc99-6e49-4b4e-959e-8f0ef7f3b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.00002:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9bf4fb7-23f1-49e9-bcac-5e49a4301d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    # importing the necessary libraries and initializing the Pinecone client\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    # from pinecone import PodSpec\n",
    "    from pinecone import Pinecone,ServerlessSpec\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "    \n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"),environment = os.environ.get('PINECONE_ENV'))\n",
    "\n",
    "        \n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)  # 512 works as well\n",
    "\n",
    "    # loading from existing index\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
    "        vector_store = PineconeVectorStore.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        # creating the index and embedding the chunks into the index \n",
    "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
    "\n",
    "        # creating a new index\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        ) )\n",
    "        \n",
    "\n",
    "        # processing the input documents, generating embeddings using the provided `OpenAIEmbeddings` instance,\n",
    "        # inserting the embeddings into the index and returning a new Pinecone vector store object. \n",
    "        vector_store = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "        \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a46564-0ef7-4fbe-bcbe-4392bc214c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pc = pinecone.Pinecone()\n",
    "    \n",
    "    if index_name == 'all':\n",
    "        indexes = pc.list_indexes().names()\n",
    "        print('Deleting all indexes ... ')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pc.delete_index(index_name)\n",
    "        print('Ok')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828e3ef4-e3d1-4a37-85ae-50d8596aa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-4', temperature=0)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.invoke(q)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab6d3f-247f-44c0-8ba5-70557a2bb618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b48be0e-6501-48e6-957f-21a4537ff5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f50d4593-aace-4094-a419-62568c03359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample.pdf\n",
      "Creating index sample and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "# Loading the pdf document into LangChain \n",
    "data = load_document('sample.pdf')\n",
    "\n",
    "# Splitting the document into chunks\n",
    "chunks = chunk_data(data)\n",
    "\n",
    "# Creating a Chroma vector store using the provided text chunks and embedding model (default is text-embedding-3-small)\n",
    "vector_store = insert_or_fetch_embeddings('sample',chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6226944c-22a5-4e08-9a93-4123ca9b22ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is the document all about', 'result': \"The document is a detailed financial report of Infosys Limited and its subsidiaries. It includes the Condensed Consolidated Financial Statements under Indian Accounting Standards (Ind AS) for the three months and year ended March 31, 2024. The report contains various financial statements such as the balance sheet, statement of profit and loss, statement of changes in equity, and statement of cash flows. It also includes an overview of the company and notes to the interim condensed consolidated financial statements, which provide additional details and explanations about the financial statements. The document also discusses the company's accounting policies, basis of consolidation, use of estimates and judgments, and other financial information such as business combinations, investments, loans, assets, liabilities, income taxes, revenue, expenses, and leases. It also includes information about legal proceedings and commitments.\"}\n"
     ]
    }
   ],
   "source": [
    "# Asking questions\n",
    "q ='what is the document all about'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3585f470-d72a-4d4c-b9cb-d355a0f8c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document is a detailed financial report of Infosys Limited and its subsidiaries. It includes the Condensed Consolidated Financial Statements under Indian Accounting Standards (Ind AS) for the three months and year ended March 31, 2024. The report contains various financial statements such as the balance sheet, statement of profit and loss, statement of changes in equity, and statement of cash flows. It also includes an overview of the company and notes to the interim condensed consolidated financial statements, which provide additional details and explanations about the financial statements. The document also discusses the company's accounting policies, basis of consolidation, use of estimates and judgments, and other financial information such as business combinations, investments, loans, assets, liabilities, income taxes, revenue, expenses, and leases. It also includes information about legal proceedings and commitments.\n"
     ]
    }
   ],
   "source": [
    "print(answer['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "319ed020-d057-450f-9e9e-feb980779c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'give total Total equity and liabilities of all year', 'result': 'The document provided does not contain information on the total equity and liabilities for any year.'}\n"
     ]
    }
   ],
   "source": [
    "# Load a Chroma vector store from the specified directory (default ./chroma_db) \n",
    "# db = load_embeddings_chroma()\n",
    "q = 'give total Total equity and liabilities of all year'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf9bf96d-d356-4385-be01-b4fc75cc172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a46ae8a-4a99-4ad4-a66c-0e5442e57122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b7f5f93-085c-4319-a6a0-e978fda9012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_pdf_text(pdf_path):\n",
    "#     text = \"\"\n",
    "#     with open(pdf_path, 'rb') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         for page in pdf_reader.pages:\n",
    "#             text += page.extract_text()\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a90359bc-b850-46cd-b060-3a3145d27270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "085b21c8-2412-4fc3-ba24-880858bba36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "778e9c15-5ca6-4294-b806-24ccf257b6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0d7537d-c734-407b-8e7e-ee88d3fe5b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the PDF file:  tsla-20231231-gen.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Splitting text into chunks...\n",
      "Creating embeddings and vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_9656\\239044759.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
      "C:\\Users\\ankit\\AppData\\Local\\Temp\\ipykernel_9656\\239044759.py:18: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm=ChatOpenAI(model=\"gpt-4\", temperature= 0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDF QnA system is ready! Type your questions below.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  what is the document all about\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The document appears to be an Annual Report on Form 10-K, which is a comprehensive report of a company's performance that must be submitted annually to the U.S. Securities and Exchange Commission. It includes information about the company's mission, products, services, and financial performance. The document also discusses the company's governance, including anti-takeover provisions, the rights and powers of the board of directors, and the terms of the company's convertible senior notes. It also includes sections on executive compensation, security ownership, and relationships and transactions.\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  give annual report\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: I'm sorry, but as an AI, I don't have the ability to provide the full annual report. The information provided only includes some parts of the report, such as the responsibility of the registrant's certifying officer and the overview and highlights for 2023. For the full annual report, you would need to refer to the original document or source.\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  give the financial report of 2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The text provides some information about the financial report of 2022, but it doesn't provide a comprehensive overview. Here's what we know:\n",
      "\n",
      "- An impairment loss of $204 million was recorded, as well as realized gains of $64 million in connection with converting holdings of digital assets into fiat currency.\n",
      "- Other expenses of $36 million were recorded during the second quarter of the year ended December 31, 2022, related to employee terminations.\n",
      "- Interest income for the year 2022 was $297 million.\n",
      "\n",
      "For a complete financial report of 2022, you should refer to the Annual Report on Form 10-K for fiscal year 2022, which was filed with the Securities and Exchange Commission on January 31, 2023.\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n",
      "[Source]: No source...\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the QnA system. Goodbye!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0fa58-a172-4f58-b2ff-1a05008a4f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
